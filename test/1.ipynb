{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from pixelist import ImagePipeline, ImageBatch, filter_decorator\n",
    "import cv2\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def load_sample_images(num_samples: int = 5) -> list[np.ndarray]:\n",
    "    \"\"\"Load sample images from the road sign dataset.\"\"\"\n",
    "    dataset = load_dataset(\"aarmn/Persian_English_Roadsign_OCR_Dataset_Relabeled\")\n",
    "    \n",
    "    # Get training split and sample randomly\n",
    "    train_data = dataset['train']\n",
    "    # Convert numpy.int32 to regular Python int\n",
    "    indices = [int(i) for i in np.random.choice(len(train_data), num_samples, replace=False)]\n",
    "    \n",
    "    # Convert images to numpy arrays\n",
    "    images = []\n",
    "    for idx in indices:\n",
    "        # Get PIL Image from dataset\n",
    "        img: Image.Image = train_data[idx]['image']\n",
    "        # Convert PIL to numpy array\n",
    "        img_array = np.array(img)\n",
    "        # Convert to grayscale if colored (RGB to GRAY)\n",
    "        if len(img_array.shape) == 3:\n",
    "            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "        images.append(img_array)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def laplacian_filter(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply Laplacian filter for edge detection.\"\"\"\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).astype(np.uint8)\n",
    "\n",
    "def prewitt_filter(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply Prewitt filter for edge detection.\"\"\"\n",
    "    kernel_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "    kernel_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])\n",
    "    \n",
    "    grad_x = cv2.filter2D(image, -1, kernel_x)\n",
    "    grad_y = cv2.filter2D(image, -1, kernel_y)\n",
    "    \n",
    "    return cv2.addWeighted(np.absolute(grad_x), 0.5, \n",
    "                          np.absolute(grad_y), 0.5, 0)\n",
    "\n",
    "def histogram_stretch(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply histogram stretching.\"\"\"\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    return np.clip((image - p2) * (255.0 / (p98 - p2)), 0, 255).astype(np.uint8)\n",
    "\n",
    "def main():\n",
    "    # Load sample images\n",
    "    print(\"Loading dataset samples...\")\n",
    "    images = load_sample_images(4)\n",
    "    \n",
    "    # Add parentheses to decorator calls\n",
    "    histogram_stretch_filter = filter_decorator()(histogram_stretch)\n",
    "    prewitt_filter_decorated = filter_decorator()(prewitt_filter)\n",
    "    laplacian_filter_decorated = filter_decorator()(laplacian_filter)\n",
    "\n",
    "    # Create sequential pipeline\n",
    "    seq_pipeline = ImagePipeline([histogram_stretch_filter, prewitt_filter_decorated, laplacian_filter_decorated])\n",
    "    seq_result = seq_pipeline.run(images=images, show=True)\n",
    "    \n",
    "    # Create parallel pipeline\n",
    "    par_pipeline = ImagePipeline([histogram_stretch_filter, (prewitt_filter_decorated, laplacian_filter_decorated)])\n",
    "    par_result = par_pipeline.run(images=images, show=True)\n",
    "    \n",
    "    print(dir(par_result))\n",
    "    print(dir(seq_result))\n",
    "\n",
    "\n",
    "main()\n",
    "print(\"All tests completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
